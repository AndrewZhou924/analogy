logger_dir : './runs'
data_path : './data'
data_name : 'vrd'

optimizer : 'adam'
num_epochs : 5
lr_update : 6
learning_rate : 0.001
batch_size : 16
start_epoch : 10
save_epoch : 5
pretrained_model : './runs/vrd_trainvalwounrel_base/model_epoch10.pth.tar'

train_split : 'trainval_unrel'
test_split : 'test'


network : 'netindepemb'
embed_size : 256
d_hidden : 256
num_layers : 2
sampler : 'priority_object'


exp_name : 'vrd_trainvalwounrel_analogy'

add_gt : True
net_unigram_s : 'appearanceprecompsubject'
net_unigram_o : 'appearanceprecompobject'
net_unigram_r : 'spatialappearanceprecomp'
net_trigram_sro : 'spatialappearanceprecomp'

net_language : 'word2vec_compositional_2fc'
criterion_name : 'logloss'

use_precompappearance : True
#use_precompobjectscore : True
num_negatives : 3


normalize_vis : False
normalize_lang : True
l2norm_input : True

use_analogy : True
analogy_type : 'hybrid'
apply_deformation : True
gamma : 'regdeep'
lambda_reg : 1
minimal_mass : 10
normalize_source : True
unique_source_random: True
detach_lang_analogy : True
embedding_type : 'aggregsourcecorrection'
sim_method : 'emb_jointspace'

alpha_r : 0.8
alpha_s : 0.1
use_target : True
thresh_method : 'top_5'
num_source_words_common : 0


# Test options
cand_test : 'candidates'
sample_negatives : 'among_vocab'
epoch_model : 'epoch15'
